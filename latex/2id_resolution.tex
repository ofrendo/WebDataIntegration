%\newpage
\section{Identity resolution}
\subsection{Gold standards}
%For each of the subsubsections below:
%Content and size of your gold standard and procedure used to create it
%Give a few corner cases
%	companies that are very similar but not the same
%	companies that are not similar but are the same
As described that we have four datasets in total , we made three types of gold standards . For the convenience of matching , entities in smaller size dataset are compared to the bigger one and all gold standards are selected by stratified distribution in ascending order . The corner cases in our project are mainly about companies which are very similar but not the same and companies have different names but are the same entity.

%Silvia/Zehui
\paragraph{Forbes and Freebase} are compared by the shared attributes : company name , country , industries , and revenue . The gold standard has 220 pairs in total with 120 false and 100 true . Types of corner cases are divided into abbreviation , Incomplete name , Similar name and Same name with different countries or industries. We took some examples as following:

\textbf{Abbreviation}: Bank of China V.S. Industrial and Commercial Bank of China (Asia) , TRUE \\
\textbf{Incomplete name}: Chevron V.S. Chevron Corporation , TRUE  \\
\textbf{Similar name}: BP V.S. TNK-BP , FALSE \\
\textbf{different country/industry}: Makita (U.S) V.S. Makita (Japan) \\

%Yiru
\paragraph{Freebase and DBpedia:} The size of gold standard between Freebase and DBpedia is 200, including 102 false cases and 98 true cases. First we choose one company in Freebase and then search it in DBpedia. If match, then put it in true case. If not, then find one which has a similar name or equivalent values in other attributes, e.g. countries or industries.
% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table}[H]
\centering
\caption{Companies that are very similar but not the same}
\label{my-label}
\begin{tabular}{llllrrclcc}
                  & \multicolumn{1}{c}{\textbf{Company ID}} & \multicolumn{1}{c}{\textbf{name}}                             & \multicolumn{1}{c}{\textbf{industries}} & \multicolumn{1}{c}{\textbf{revenue}} & \multicolumn{1}{c}{\textbf{numberOfEmployees}}        & \textbf{dateFounded} & \multicolumn{1}{c}{\textbf{keyPeople}}     & \textbf{countries}                                     & \textbf{location}                                                \\
\multirow{2}{*}{} & DBPedia\_Company\_4511                  & http://dbpedia.org/resource/E.ON\_Russia                      & http://dbpedia.org/resource/Electricity & 2.40E+09                             & 5300                                                  & 2006                 & Maxim Gennadyevich Shirokov;;Yuri Sablukov & \multicolumn{1}{l}{http://dbpedia.org/resource/Russia} & \multicolumn{1}{l}{http://dbpedia.org/resource/Surgut}           \\
                  & Freebase\_Company\_935                  & E.ON                                                          & Utilities;;Combination Utilities, NEC   & 94356000000                          & \begin{tabular}[c]{@{}r@{}}87815\\ 80612\end{tabular} & 2000-06-16           & Johannes Teyssen                           & Germany                                                & Düsseldorf                                                       \\
\multirow{2}{*}{} & DBPedia\_Company\_10348                 & http://dbpedia.org/resource/Okinawa\_Electric\_Power\_Company &                                         & 162501                               & 2495                                                  & 1972                 &                                            & \multicolumn{1}{l}{http://dbpedia.org/resource/Japan}  & \multicolumn{1}{l}{http://dbpedia.org/resource/Urasoe,\_Okinawa} \\
                  & Freebase\_Company\_2077                 & Oki Electric Industry                                         & Electronics                             &                                      & 17415                                                 & 1881-01              & Hideichi Kawasaki                          & Japan                                                  & Minato                                                          
\end{tabular}
\end{table}

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
\begin{table}[H]
\centering
\caption{Companies that are not similar but are the same}
\label{my-label}
\begin{tabular}{llllrrclcc}
                  & \multicolumn{1}{c}{\textbf{Company ID}} & \multicolumn{1}{c}{\textbf{name}}            & \multicolumn{1}{c}{\textbf{industries}}                                                                                                & \multicolumn{1}{c}{\textbf{revenue}} & \multicolumn{1}{c}{\textbf{numberOfEmployees}} & \textbf{dateFounded} & \multicolumn{1}{c}{\textbf{keyPeople}}             & \textbf{countries}                                    & \textbf{location}                                      \\
\multirow{2}{*}{} & DBPedia\_Company\_11805                 & http://dbpedia.org/resource/Repsol           & http://dbpedia.org/resource/Petroleum\_industry                                                                                        & 56298                                & 24214                                          & 1987                 & Antonio Brufau Niubó (, Josu Jon Imaz San Miguel ) & \multicolumn{1}{l}{http://dbpedia.org/resource/Spain} & \multicolumn{1}{l}{http://dbpedia.org/resource/Madrid} \\
                  & Freebase\_Company\_2318                 & Repsol YPF S.A.                              & Crude Petroleum and Natural Gas Extraction;;Petroleum industry                                                                         & 72705600000                          & 36700                                          & 1986                 & Antonio Brufau Niubó                               & Spain                                                 & Madrid                                                 \\
\multirow{2}{*}{} & DBPedia\_Company\_15286                 & http://dbpedia.org/resource/Wacom\_(company) & http://dbpedia.org/resource/Input\_device;;http://dbpedia.org/resource/Software                                                        &                                      & 1427                                           & 1983                 & Masahiko Yamada                                    & Japan                                                 & Kazo, Saitama                                          \\
                  & Freebase\_Company\_3052                 & Wacom                                        & Software;;All Other Miscellaneous Electrical Equipment and Component Manufacturing;;Electrical Machinery, Equipment, and Supplies, NEC &                                      & 584                                            & 1983-07-12           & Masahiko Yamada                                    & Japan                                                 & Saitama                                               
\end{tabular}
\end{table}

%Silvia/Zehui
\paragraph{DBPedia companies and DBPedia} locations has two shared attributes: location city and location country . Because city name extracted from DBPedia Location has multiple values due to muti-districts in one city , we defined the city without specific district name as the only true value for integration . The total gold standards size for this part is 270 pairs with 190 false and 80 true.\\
Example of corner cases: \\
New York V.S. New York City , TRUE
New York V.S. Syracuse, New York , FALSE
http://dbpedia.org/resource/New\_York\_City V.S. New York City , TRUE
http://dbpedia.org/resource/New\_York\_City V.S. Syracuse, New York , FALSE


\newpage
\subsection{Matching rules}
%Oliver
This section explains the matching rules we tried in order to generate correspondences accurately. We matched the following datasets with each other:
\begin{itemize}[noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt]
\item Forbes vs Freebase
\item Freebase vs DBpedia
\item DBpedia companies vs DBpedia locations
\end{itemize}

%%%%%%%%%%%%%%BEGIN TABLE

\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|l|l|}
\hline
\textbf{Attribute} & \textbf{MatchingRule} & \textbf{P} & \textbf{R} & \textbf{F1} \\ \hline
\multicolumn{5}{|l|}{\textbf{Forbes vs Freebase}} \\ \hline
\multirow{2}{*}{name} & Equals & 1,0000 & 0,7500 & 0,8571 \\ \cline{2-5} 
 & Levenshtein & 0,8571 & 1,0000 & 0,9231 \\ \hline
\multirow{3}{*}{countries} & Equals & 0,8571 & 1,0000 & 0,9231 \\ \cline{2-5} 
 & Jaccard & 0,8571 & 1,0000 & 0,9231 \\ \cline{2-5} 
 & Highest Jaccard & 0,8571 & 1,0000 & 0,9231 \\ \hline
\multirow{2}{*}{industries} & Jaccard & 0,9091 & 0,8333 & 0,8696 \\ \cline{2-5} 
 & \begin{tabular}[c]{@{}l@{}}Combination of Jaccard\\ and Levenshtein\end{tabular} & 0,8571 & 1,0000 & 0,9231 \\ \hline
\begin{tabular}[c]{@{}l@{}}revenue/\\ profit\end{tabular} & \begin{tabular}[c]{@{}l@{}}PercentageSimilarity\\ (max\_percentage=0.5)\end{tabular} & 0,8571 & 1,0000 & 0,9231 \\ \hline
\multicolumn{5}{|l|}{\textbf{Freebase vs DBpedia}} \\ \hline
\begin{tabular}[c]{@{}l@{}}revenue/\\ numberOfEmployees\end{tabular} & \begin{tabular}[c]{@{}l@{}}PercentageSimilarity\\ (max\_percentage=0.5)\end{tabular} & 0,9167 & 0,9167 & 0,9167 \\ \hline
dateFounded & \begin{tabular}[c]{@{}l@{}}YearSimilarity\\ (maxDifference=20)\end{tabular} & 0,9167 & 0,9167 & 0,9167 \\ \hline
\multirow{2}{*}{keyPeople} & Jaccard & 0,9167 & 0,9167 & 0,9167 \\ \cline{2-5} 
 & \begin{tabular}[c]{@{}l@{}}Combination of Jaccard\\ and Levenshtein\end{tabular} & 0,9167 & 0,9167 & 0,9167 \\ \hline
\multirow{2}{*}{locations} & Jaccard & 0,9167 & 0,9167 & 0,9167 \\ \cline{2-5} 
 & Highest Jaccard & 0,9167 & 0,9167 & 0,9167 \\ \hline
\multicolumn{5}{|l|}{\textbf{DBpedia companies vs DBpedia locations}} \\ \hline
countries & Highest Jaccard & 0,9706 & 0,9429 & 0,9565 \\ \hline
\multirow{2}{*}{locations} & Jaccard & 0,9630 & 0,7429 & 0,8387 \\ \cline{2-5} 
 & Highest Jaccard & 0,9706 & 0,9429 & 0,9429 \\ \hline
\end{tabular}
\caption{Matching rule accuracies}
\label{my-label}
\end{table}

%%%%%%%%%%%%%%END TABLE

In particular the rules for \texttt{name}, \texttt{industries} and \texttt{locations} show different results. For \texttt{name} we chose to use Levenshtein because of misspellings, or because of the company type (e.g. "Inc." or "PLC"). However, this also introduces some problematic cases such as "West Japan Railway" and "East Japan Railway", which are different companies but possess very similar attribute values and also generate a very high Levenshtein similarity. For \texttt{industries} we tried Jaccard first. This however is not an accurate measure of similarity because of slight differences like "Transport" and "Transportation". As such we chose to use a combination of Jaccard and Levenshtein which led to better results:

$$sim_{Jaccard+Levenshtein} = \frac{\sum_{x,y} max(sim_{Levenshtein}(x,y))} {|x|+|y| - \sum_{x,y} max(sim_{Levenshtein}(x,y))}$$

To give an example of two companies with two industries each: "Computer, Transportation" and "Computers, Transport" would generate a similarity of 0 with Jaccard but 0.75 with our approach. We used the same approach for comparing \texttt{keyPeople}, where misspellings of names are more important. \texttt{locations} and \texttt{countries} were compared using \textit{Highest Jaccard}: This means we compared each location of an entity with each location of another entity using Jaccard and then picked the highest value. To give an example: Comparing a company with two locations "New York" and "London" with another company with only one location "New York City" would give bad results using \textit{Equals} or \textit{Levenshtein}, which is why we chose to use the highest Jaccard value. Very often there were entities with multiple countries or locations but only single intersections. Due to the sparsity and potential unreliability of Freebase and DBpedia we wanted the similarity to reflect this. Lastly we compared numeric attributes such as \texttt{Revenue} using the PercentageSimilarity: However numeric data from Freebase and DBpedia is too sparse, unreliable or outdated. Learning a matching rule via linear regression confirms this by assigning weights of 0 to both these attributes.




%HARD CASES
%Vodafone, VODAFONE PLC (TRUE)
%China Pacific Insurance, CHINA LIFE INSURANCE
%Central Japan Railway, EAST JAPAN RAILWAY (FALSE)
%Vodafone, Vodafone Group plc (TRUE)
%Syracuse, Utah AND Syracuse, New York
%"Chicago and Nashville" as single attribute from DBpedia

%EXAMPLE FOR HIGHEST JACCARD 
%	C1=New York, Chicago. C2 New York. Should be correspondence, so similarity = 1
%	Couldn't just take highest equals because of New York and New York City for example
	
	
\subsection{Blocking functions}
%Oliver
Table \ref{tableBlockingFunctions} shows the blocking functions we tried and used in our project. For the comparison of the Forbes and Freebase datasets a partitioning by \texttt{countries} shows good results, which is consistent with the high density of the attribute in both datasets. We also tried a sorted neighbourhood approach on the same attribute which seemed to be less effective. Using a cross product approach for comparing Freebase with DBpedia was impossible due to the large size of DBpedia. As such we tried partitioning by \texttt{countries}, \texttt{dateFounded} (where the blocking key is $year/20$) and a combination of the two. The combination reflects our own implementation of a partitioning blocker, where we generate a match to be evaluated if the one of the two blocking keys are the same. This shows the best results because both attributes are relatively, but not completely, dense in both datasets, which is why the reduction ratio is lower then when using only one of the two. When comparing companies with locations from the DBpedia datasets \texttt{countries} is the only possible blocking key. 

%%%%%%%%%%%%%%BEGIN TABLE

\begin{table}[H]
\centering
\begin{tabular}{|l|l|c|c|c|l|l|l|}
\hline
\multicolumn{1}{|c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Dataset \\ Comparison\end{tabular}}} & \multicolumn{1}{c|}{\textbf{\begin{tabular}[c]{@{}c@{}}Blocking \\ function\end{tabular}}} & \textbf{Time} & \textbf{Match} & \textbf{Ratio} & \multicolumn{1}{c|}{\textbf{P}} & \multicolumn{1}{c|}{\textbf{R}} & \multicolumn{1}{c|}{\textbf{F1}} \\ \hline
\multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}Forbes vs \\ Freebase\end{tabular}} & CrossProduct & 00:32 & 509 & 1,00 & \multicolumn{1}{c|}{0,86} & \multicolumn{1}{c|}{1,00} & \multicolumn{1}{c|}{0,92} \\ \cline{2-8} 
 & \begin{tabular}[c]{@{}l@{}}SortedNeigh.\\ (Country)\end{tabular} & 00:05 & 319 & 6,80 & \multicolumn{1}{c|}{0,87} & \multicolumn{1}{c|}{0,58} & \multicolumn{1}{c|}{0,70} \\ \cline{2-8} 
 & \begin{tabular}[c]{@{}l@{}}Partitioning\\ (Country)\end{tabular} & 00:02 & 425 & 20,19 & 0,86 & 1,00 & 0,92 \\ \hline
\multirow{3}{*}{\begin{tabular}[c]{@{}l@{}}Freebase vs \\ DBpedia\end{tabular}} & \begin{tabular}[c]{@{}l@{}}Partitioning\\ (Country)\end{tabular} & 00:44 & 576 & 15,92 & 0,90 & 0,75 & 0,82 \\ \cline{2-8} 
 & \begin{tabular}[c]{@{}l@{}}Partitioning\\ (DateFounded)\end{tabular} & 00:39 & 496 & 9,43 & 0,89 & 0,67 & 0,76 \\ \cline{2-8} 
 & \begin{tabular}[c]{@{}l@{}}Partitioning\\ (Combination)\end{tabular} & 01:22 & 671 & 6,13 & 0,92 & 0,92 & 0,92 \\ \hline
\begin{tabular}[c]{@{}l@{}}Companies\\ vs\\ Locations\end{tabular} & \begin{tabular}[c]{@{}l@{}}Partitioning\\ (Country)\end{tabular} & 00:41 & 7.921 & 4,11 & 0,97 & 0,94 & 0,96 \\ \hline
\end{tabular}
\caption{Blocking functions}
\label{tableBlockingFunctions}
\end{table}

%%%%%%%%%%%%%%END TABLE

%Notes on blocking function:
%Freebase vs Forbes: 
%- Country is always available in Forbes, sparse in Freebase (EXACT NUMBER)

%Freebase vs DBPedia:
%- Country is somewhat sparse in both datasets (EXACT NUMBER)
%- DateFounded somewhat sparse in both (EXACT NUMBER)

%Company vs Location
%- Country is only way to go

%Own idea: Own implementation of partitioning blocker, but more fuzzy logic
%- I.E. Country first, then date, then location or so as alternative (EXACT NUMBER)
%- Generate more pairs, matching rule will take care if its same company or not- more conservative approach


\subsection{Learning matching rules}
%Oliver
We were able to improve the results of our identity resolution by learning the weights for a linear matching rule from a linear regression in RapidMiner over our handwritten rules. To give an example, the learned weights for the datasets from Freebase and DBpedia are as follows. Interestingly, both \texttt{keyPeople} and \texttt{locations} seem to be important,  while the weights for both numeric attributes \texttt{revenue} and \texttt{numberOfEmployees} is assigned a weight of 0, indicating the attributes are not very useful for an accurate comparison. Lastly the \texttt{name} attribute has the highest weight, as expected.

\begin{center}
\begin{tabular}{lrlr}
name & 0.689       & revenue & 0.000\\
countries & 0.088  & numberOfEmployees & 0.000\\
industries & 0.025 & keyPeople & 0.377\\
dateFounded & 0.170& locations & 0.218\\
\textit{intercept} & -0.135 &  & 
\end{tabular}
\end{center}

%\begin{array}
%x & y \\
%z & w 
%\end{array}
%


%Using linear regression etc
%Why was this better than handwritten one
%Discussion of both learned rules







